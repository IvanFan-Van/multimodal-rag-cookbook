{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.9), please consider upgrading to the latest version (0.3.10).\n",
      "Path to dataset files: D:\\AppData\\kaggle\\datasets\\sujaykapadnis\\dog-breeds\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"sujaykapadnis/dog-breeds\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "breed_traits = pd.read_csv(os.path.join(path, \"breed_traits.csv\"))\n",
    "breed_rank = pd.read_csv(os.path.join(path, \"breed_rank.csv\"))\n",
    "breed_traits_long = pd.read_csv(os.path.join(path, \"breed_traits_long.csv\"))\n",
    "trait_description = pd.read_csv(os.path.join(path, \"trait_description.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# 获取 pdf 数据\n",
    "\n",
    "links = breed_rank[\"links\"].tolist()\n",
    "pdf_urls = []\n",
    "pdf_base_url = \"https://images.akc.org/pdf/breeds/standards/\"\n",
    "breed_names = []\n",
    "for link in links:\n",
    "    breed_name = link.rstrip(\"/\").split(\"/\")[-1]\n",
    "    breed_names.append(breed_name)\n",
    "    words = [word.capitalize() for word in breed_name.split(\"-\")]\n",
    "    breed_name = \"\".join(words)\n",
    "    pdf_urls.append(os.path.join(pdf_base_url, breed_name + \".pdf\"))\n",
    "\n",
    "def download_breed_pdf(pdf_url, breed_name):\n",
    "    pdf_dir = Path(\"breed_pdfs\")\n",
    "    pdf_dir.mkdir(exist_ok=True)\n",
    "    pdf_path = pdf_dir / f\"{breed_name}.pdf\"\n",
    "\n",
    "    try:\n",
    "        # 下载PDF文件\n",
    "        response = requests.get(pdf_url, stream=True, verify=False)\n",
    "        response.raise_for_status()  # 检查是否下载成功\n",
    "        \n",
    "        # 保存文件\n",
    "        with open(pdf_path, 'wb') as pdf_file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    pdf_file.write(chunk)\n",
    "        \n",
    "        print(f\"成功下载PDF文件: {pdf_path}\")\n",
    "        return str(pdf_path)\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"下载PDF时发生错误: {e}\")\n",
    "    return None\n",
    "\n",
    "for url, name in zip(pdf_urls, breed_names):\n",
    "    download_breed_pdf(url, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"ajinkyakolhe112/dog_breed_classification_kaggle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AppData\\huggingface\\modules\\transformers_modules\\jinaai\\jina-clip-implementation\\51f02de9f2cf8afcd3bac4ce996859ba96f9f8e9\\modeling_clip.py:140: UserWarning: Flash attention is not installed. Check https://github.com/Dao-AILab/flash-attention?tab=readme-ov-file#installation-and-features for installation instructions, disabling\n",
      "  warnings.warn(\n",
      "D:\\AppData\\huggingface\\modules\\transformers_modules\\jinaai\\jina-clip-implementation\\51f02de9f2cf8afcd3bac4ce996859ba96f9f8e9\\modeling_clip.py:175: UserWarning: xFormers is not installed. Check https://github.com/facebookresearch/xformers?tab=readme-ov-file#installing-xformers for installation instructions, disabling\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# 初始化模型和处理器\n",
    "model = AutoModel.from_pretrained(\"jinaai/jina-clip-v2\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检索回来的时候, 不单独检索图片以及文本, 而是检索回一个文档, 这个文档包含了图片和文本\n",
    "```python\n",
    "Document {\n",
    "    text: string,\n",
    "    images: Image[],\n",
    "    metadata: {\n",
    "        source: string,\n",
    "        index: number\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "问题是如何处理这个文档, 使其包含图片以及位置信息\n",
    "类似marker-pdf的库好像可以将链接嵌入到 markdown 文档中, 如果 chunking 的时候把链接一起包含了, 那么那个 Document 就会包含图片了. 在 markdown 中的链接应该包含图片实际存储的位置, 然后将图片读取并存储到Document内"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncate_dim = 512\n",
    "\n",
    "def extract_image_features(images):\n",
    "    image_features = model.encode_image(images, truncate_dim=truncate_dim)\n",
    "    return image_features\n",
    "\n",
    "def extract_text_features(texts):\n",
    "    text_features = model.encode_text(texts, truncate_dim=truncate_dim)\n",
    "    return text_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:04<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "# === 构建 Image Embedding 数据库 ===\n",
    "image_features_list = []\n",
    "for img in tqdm(ds['train'][:100]['image']):\n",
    "    features = extract_image_features(img)\n",
    "    image_features_list.append(features)\n",
    "\n",
    "image_features = np.vstack(image_features_list)\n",
    "df = pd.DataFrame(image_features)\n",
    "df.to_parquet(r\"D:\\HKU\\Inno Wing RA\\multimodal-rag-tutorial\\db\\image_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3173/3173 [25:19<00:00,  2.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# === 构建 Text Embedding 数据库 ===\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "\n",
    "# context chunking\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "markdown_dir = Path(r\"d:/HKU/Inno Wing RA/multimodal-rag-tutorial/md_outputs\")\n",
    "documents = []\n",
    "for path in markdown_dir.rglob(\"*.md\"):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "        documents.append(content)\n",
    "\n",
    "chunks = splitter.split_text(\"\\n\\n\".join(documents))\n",
    "\n",
    "text_features_list = []\n",
    "for doc in tqdm(chunks):\n",
    "    features = extract_text_features(doc)\n",
    "    text_features_list.append(features)\n",
    "\n",
    "text_features = np.vstack(text_features_list)\n",
    "df = pd.DataFrame(text_features)\n",
    "df.to_parquet(r\"D:\\HKU\\Inno Wing RA\\multimodal-rag-tutorial\\db\\text_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(chunks)\n",
    "df.to_parquet(r\"D:\\HKU\\Inno Wing RA\\multimodal-rag-tutorial\\db\\text_chunks.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_db = pd.read_parquet(r\"D:\\HKU\\Inno Wing RA\\multimodal-rag-tutorial\\db\\image_features.parquet\").to_numpy()\n",
    "text_db = pd.read_parquet(r\"D:\\HKU\\Inno Wing RA\\multimodal-rag-tutorial\\db\\text_features.parquet\").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 512)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_db.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3173, 512)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_db.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
